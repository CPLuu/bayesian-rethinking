


get_ipython().run_line_magic("run", " init_notebook.py")





# Given N = 15 tosses
sample = 4*"W" + 11*"L"

def count_proportion(sample: str):  # breaking down num of W and L in given sample
    nW = len(sample.replace("L", ""))
    nL = len(sample) - nW
    return nW, nL

nW, nL = count_proportion(sample)


# Assuming infinite possibilities of faces, globe tossing data would follow the beta distribution
# Manual coding of the idealized beta distribution
from scipy.special import factorial
def beta(sample: str, p):
    nW, nL = count_proportion(sample)
    posteriorP = factorial(nW + nL + 1) / (factorial(nW) * factorial(nL)) * p**nW * (1-p)**nL
    return posteriorP

pWater = np.linspace(0, 1, 11)  # Given that there are inf faces, will will select a set of proportions of face with water for input into beta
posteriorP = beta(sample, pWater)

# Using scipy to create beta distr obj, useful for sampling from
posteriorBeta = stats.beta(nW+1, nL+1)

posteriorBeta_samples = posteriorBeta.rvs(500)  # sampling for pWater, frequency follows that of the pdf

# Graph posterior distribution: prob(p | W, L) <- p
plt.plot(pWater, posteriorP, color=color, linewidth=4, alpha=.5, label='continuous beta')
plt.hist(posteriorBeta_samples, bins=50, density=True, label='sampling from beta');
plt.xlabel("proportion water")
plt.ylabel("density ()")
plt.legend();





# Sampling from the posterior
def simulate_toss(p, N):
    sample = np.random.choice(list("WL"),  size=N, p=np.array([p, 1-p]), replace=True)
    sample = ''.join(sample)
    nW, nL = count_proportion(sample)
    return nW

N = 5;  # Next 5 tosses
posteriorBeta_sampled_p = posteriorBeta.rvs(10000)
posterior_predictive_distribution = [simulate_toss(p, N) for p in posteriorBeta_sampled_p]

# Graph posterior predictive distribution: 
plt.hist(posterior_predictive_distribution, bins=range(0,7), align='left', rwidth=.7)
plt.xlabel("Number of water in the next N tosses")
plt.ylabel("density")





# Prob of W>= 3 in N=5 is Prob W = 3 or 4 or 5
posterior_predictive_distribution_array = np.array(posterior_predictive_distribution)

pW = ((posterior_predictive_distribution_array) >= 3).sum() / len(posterior_predictive_distribution_array)

print(pW)





# posteriorP_Beta = factorial(nW + nL + 1) / (factorial(nW) * factorial(nL)) * p**nW * (1-p)**nL
def posteriorP_unknownN(nw, p):
    nL = np.arange(nW, 11, 1)
    posteriorP_Binom = factorial(nW + nL) / (factorial(nW) * factorial(nL)) * p**nW * (1-p)**nL
    return nL, posteriorP_Binom


nW=5;
p=0.7;
nL, posteriorP_Binom = posteriorP_unknownN(nW, p)

plt.plot(nL, posteriorP_Binom , color=color, linewidth=4, alpha=.5, label='continuous beta')
plt.xlabel("nL")
plt.ylabel("posterior Prob(p=0.7 | N, nW = 5)")
plt.legend();
