


get_ipython().run_line_magic("run", " init_notebook.py")








utils.draw_causal_graph(
    edge_list=[
        ("p", "W"),
        ("p", "L"),
        ("N", "L"),
        ("N", "W")
    ],
    graph_direction="LR",
    node_props={
        "p": {"color": "red"}
    },
    edge_props={
        ("p", "W"): {"label": "influence"}
    }
)








def calculate_n_ways_possible(observations: str, n_water: int, resolution: int = 4):
    """
    Calculate the number of ways to observing water ('W') given the toss of a globe
    with `resolution` number of sides and `n_water` faces.
    Note: this method results in numerical precision issues (due to the product) when the
    resolution of 16 or so, depending on your system.
    """
    assert n_water <= resolution  # check for fewer water faces than total faces
    
    # Convert observation string to an array
    observations = np.array(list(observations.upper()))
    # Create n-sided globe with possible outcomes
    n_land = resolution - n_water
    possible = np.array(list("L" * (n_land)) + list("W" * n_water))
    
    # Given possible w-l config, tally number of ways sample could have been collected at each iteration of observation
    # Here we use brute-force, but we could also use the analytical solution below
    ways = []
    for obs in observations:
        ways.append((possible == obs).sum())
        
    p_water = n_water / resolution
    # perform product of array elements to get number of combo --- done in log space for numerical precision
    n_possible_ways = np.round(np.exp(np.sum(np.log(ways)))).astype(int)
    return n_possible_ways, p_water



def run_globe_tossing_simulation(observations, resolution, current_n_possible_ways=None):
    """
    Simulate the number of ways you can observe water ('W') for a globe of `resolution`
    sides, looping through variations of globes with water face.
    """
    # For Bayesian updates
    current_n_possible_ways = current_n_possible_ways if current_n_possible_ways is not None else np.array([])

    print(f"Observations: '{observations}'")
    current_p_water = np.array([])
    for n_W in range(0, resolution + 1):
        n_L = resolution - n_W
        globe_sides = "W" * n_W + "L" * n_L
        n_possible_ways, p_water = calculate_n_ways_possible(observations, n_water=n_W, resolution=resolution)
        print(f"({n_W+1}) {globe_sides} p(W) = {p_water:1.2}  \t\t  {n_possible_ways} Ways to Produce")

        current_p_water = np.append(current_p_water, p_water)
        current_n_possible_ways = np.append(current_n_possible_ways, n_possible_ways)

    return current_n_possible_ways, current_p_water


RESOLUTION = 4
observations = "WLW"
current_n_possible_ways, current_p_water = run_globe_tossing_simulation(observations, resolution=RESOLUTION)





new_observation_possible_ways, _ = run_globe_tossing_simulation("W", resolution=RESOLUTION)

# Online update: multiply old * new combo number
current_n_possible_ways *= new_observation_possible_ways

print("\nUpdated Possibilities given new observation:")
for ii in range(0, RESOLUTION + 1):
    print(f"({ii+1}) p(W) = {current_p_water[ii]:1.2}\t\t{int(current_n_possible_ways[ii])} Ways to Produce")






RESOLUTION = 4
observations = "WLWWWLWLW"
n_W = len(observations.replace("L", ""))
n_L = len(observations) - n_W

n_possible_ways, p_water = run_globe_tossing_simulation(observations, resolution=RESOLUTION)








def calculate_analytic_n_ways_possible(p, n_W, n_L, resolution=RESOLUTION):
    """This scales much better than the brute-force method"""
    analytic_n_possible_ways = (resolution * p) ** n_W * (resolution - resolution * p) ** n_L
    return analytic_n_possible_ways

analytic_n_possible_ways = np.array([calculate_analytic_n_ways_possible(p, n_W, n_L) for p in p_water])

print(analytic_n_possible_ways)
print(analytic_n_possible_ways == n_possible_ways)  # comparing n ways generated from from the analytic model vs combonatoric simulation at each of the 4 p values





n_possible_probabilities = n_possible_ways / n_possible_ways.sum()

print("Proportion\tWays\tProbability")
for p, n_w, n_p in zip(p_water, n_possible_ways, n_possible_probabilities):
    print(f"{p:1.12}\t\t{n_w:0.0f}\t{n_p:1.2f}")

# Histogram
p_water = np.linspace(0, 1, RESOLUTION+1)
plt.subplots(figsize=(5, 5))
plt.bar(x=p_water, height=n_possible_probabilities, width= 0.8 / RESOLUTION, color='k')
plt.xticks(p_water);
plt.ylabel("probability")
plt.xlabel("proportion water");








from pprint import pprint


np.random.seed(1)
def simulate_globe_toss(p=0.7, N=9):
    """Simulate N globe tosses with a specific/known proportion
    p: float -> The propotion of water
    N: int   -> Number of globe tosses
    """
    return np.random.choice(list("WL"),  size=N, p=np.array([p, 1-p]), replace=True)


print(simulate_globe_toss())


samples = [simulate_globe_toss(p=.5, N=10).tolist() for _ in range(10)]  # change p to test extreme conditions
pprint(samples)





# Large N should converge to known p
known_p = 0.5

simulated_ps = []
sample_sizes = np.linspace(10, 100_000, 10)
for N in sample_sizes:
    outcomes = simulate_globe_toss(p=known_p, N=int(N))
    simulated_p = np.sum(outcomes == 'W') / N
    print(simulated_p)
    simulated_ps.append(simulated_p)
    
plt.axhline(known_p, label=f"Known p={known_p}", color='k', linestyle='--')
plt.legend();
plt.plot(sample_sizes, simulated_ps);





def compute_posterior(observations, resolution=RESOLUTION):
    """
    fn apply the analytic way of calculating n ways of arriving at the obs given each p_water and resolution # of faces
    """
    n_W = len(observations.replace("L", ""))
    n_L = len(observations) - n_W
    
    p_water = np.linspace(0, 1, resolution+1)
    n_possible_ways = np.array([calculate_analytic_n_ways_possible(p, n_W, n_L, resolution) for p in p_water])
    posterior = n_possible_ways / n_possible_ways.sum()
    # probs = np.linspace(0, 1, resolution+1)
    return posterior, p_water


def plot_posterior(observations, resolution=RESOLUTION, ax=None):
    """
    Plotting proportion of water, and their probability of occuring in an earth with resolution # of faces
    """
    posterior, p_water = compute_posterior(observations, resolution=resolution)
    if ax is not None:
        plt.sca(ax)
    plt.bar(x=p_water, height=posterior, width= .8 / resolution, color='k')
    plt.xticks(p_water[::2], rotation=45);
    plt.ylabel("probability")
    plt.xlabel("proportion of water")
    plt.title(f"Posterior Calculated\nfrom # Samples: {len(observations)}")
    return posterior, p_water


observations = "WLWWWLWLW"
posterior, p_water = plot_posterior(observations, resolution=4)


resolution=10
p = .6
N = 100

# Given a p and known resolution, simulate sampling of N obs
# np.random.seed(2) # seed fix random generator
simulated_observations = "".join(simulate_globe_toss(p=p, N=N))  # converting array into string for input into plot_posterior fN
sampled_n_water = len(simulated_observations.replace("L", ""))/N

# Pass sample and resolution (p kept hidden) into fN using analytic estimator to calculate posterior probability of various p_water
posterior, p_water = plot_posterior(simulated_observations, resolution)
plt.axvline(p, color='C0', label='True Water Proportion')
plt.axvline(sampled_n_water, color='C1', label='Sampled Water Proportion')
plt.legend();

# -> most likely p_water to have generatered the sample is p_water with highest probability





np.random.seed(12)
p = .7
simulated_observations = "".join(simulate_globe_toss(p=p, N=30))
_, axs = plt.subplots(1, 3, figsize=(10, 4))
for ii, possibilities in enumerate([5, 10, 20]):
    plot_posterior(simulated_observations, resolution=possibilities, ax=axs[ii])
    plt.ylim([-.05, 1])
    axs[ii].set_title(f"{possibilities} possibilities")








from scipy.special import factorial

# Estimator based on the beta distribution
def beta(W, L, p):
    return factorial(W + L + 1) / (factorial(W) * factorial(L)) * p ** W * (1-p) ** L


def plot_beta_from_observations(observations: str, resolution: int = 50, **plot_kwargs):
    """Calcualte the posterior for a string of observations"""
    n_W = len(observations.replace("L", ""))
    n_L = len(observations) - n_W
    proportions_water = np.linspace(0, 1, resolution)
        
    posterior_p = beta(n_W, n_L, proportions_water)
    plt.plot(proportions_water, posterior_p, **plot_kwargs)
    plt.yticks([])
    plt.title(observations)
    

# Tossing the globe
observations = "WLWWWLWLW"
fig, axs = plt.subplots(3, 3, figsize=(8, 8))
for ii in range(9):
    ax = axs[ii // 3][ii % 3]
    plt.sca(ax)
    
    # Plot previous posterior distribution as dash
    if ii > 0:
        plot_beta_from_observations(observations[:ii], color='k', linestyle='--')
    else:  # First observation, no previous data
        plot_beta_from_observations('', color='k', linestyle='--')

    # Plot updated posterior distr as solid line
    color = 'C1' if observations[ii] == 'W' else 'C0'  # blue line if new obs is W
    plot_beta_from_observations(observations[:ii+1], color=color, linewidth=4, alpha=.5)
    
    if not ii % 3:
        plt.ylabel("posterior probability")
    











a, b = 9, 1 # a = n_water; b = n_land

# sampling the posterior, a beta destribution
beta_posterior = stats.beta(a+1, b+1)  #  +1 since the beta equation used by stat has a 'a-1' exponent that our manual equations has taken down and replaced as 'a' (same for 'b')
bets_posterior_samples = beta_posterior.rvs(size=500)
plt.hist(bets_posterior_samples, bins=50, density=True, label='samples');

# ideal Beta distribution
p_water = np.linspace(0, 1, 100)
plt.plot(p_water, beta(a, b, p_water), linewidth=3, color='k', linestyle='--', label='beta distribution')  # Beta defined manually earlier

plt.xlabel("proportion water")
plt.ylabel("density ()")
plt.legend();





# 1. Sampling p's from the posterior distribution
posterior_samples = beta_posterior.rvs(size=10000)

# 2. Here we use each sampled p from the posterior to simulate sampling 10 observations from our generative model
posterior_predictive = [(simulate_globe_toss(p, 10) == 'W').sum() for p in posterior_samples]
ppd_unique, ppd_counts = np.unique(posterior_predictive, return_counts=True)

# Sampling with a p in the  beta distribution - for contrast with when p is sampled, rather than selected
specific_prob = 0.64
specific_predictive = [(simulate_globe_toss(specific_prob, 10) == 'W').sum() for _ in posterior_samples]
specific_unique, specific_counts = np.unique(specific_predictive, return_counts=True)

plt.bar(specific_unique, specific_counts, width=.5, color='k', label=f'simulation at p={specific_prob:1.2}');
plt.bar(ppd_unique, ppd_counts, width=.2, color='C1', label='posterior predictive');
plt.xlabel("number of 'W' samples")
plt.ylabel('count')
plt.legend();












utils.draw_causal_graph(
    edge_list=[
        ("p", "W"),
        ("W", "W*"),
        ("M", "W*"),
        ("N", "W")
    ],
    node_props={
        "p": {"color": "red", "style": "dashed"},
        "W": {"style": "dashed", "label": "actual W"},
        "W*": {"style": "dashed", "label": "noisy W = W*"},
        "unobserved": {"style": "dashed"},
        "M": {"label": "measurement error, M"}
    },
    graph_direction="LR"
)





def simulate_noisy_globe_toss(p=0.7, N=9, error_rate=0.1):
    # True sample
    sample = np.random.choice(list("WL"),  size=N, p=np.array([p, 1-p]), replace=True)
    
    # Error-induced sample
    error_trials = np.random.rand(N) < error_rate
    errors_effect_sample_trials = (sample == 'W') & error_trials
    sample[errors_effect_sample_trials] = 'L'
    return error_trials, sample
    
simulate_noisy_globe_toss()





def calculate_unnormalized_n_ways_possible_with_error(p, n_W, n_L, error_rate=0.1):
    n_W_error = (p * (1 - error_rate) + ((1 - p) * error_rate)) ** n_W 
    n_L_error = ((1 - p) * (1 - error_rate) + (p * error_rate)) ** n_L
    return n_W_error * n_L_error

a, b = 6, 3
resolution = 100
proportions = np.linspace(0, 1, resolution)
error_rate = 0.1
error_posterior = np.array(
    [calculate_unnormalized_n_ways_possible_with_error(p, a, b, error_rate) for p in proportions]
)

beta_posterior = beta(a, b, proportions)

# Infer normalization constant Z from distribution
error_posterior *= resolution / error_posterior.sum()
beta_posterior *= resolution / beta_posterior.sum()



plt.subplots(figsize=(6, 6))
plt.plot(proportions, beta_posterior, label='previous posterior', color='k', linewidth=4)
plt.plot(proportions, error_posterior, label=f'misclassification posterior\n(error rate={error_rate:1.2})', linewidth=4)
plt.xlabel("proportion of water")
plt.ylabel("posterior probability")
plt.legend();



